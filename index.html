<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Why Turing.jl? 15 May 2025</title>
        <link rel="stylesheet" href="main.css">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/styles/atom-one-light.css">
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/highlight.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/languages/python.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/languages/julia.min.js"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.11.1/languages/stan.min.js"></script>
        <script>hljs.highlightAll();</script>
    </head>
    <body>
        <h1 id="toc">Table of contents - code snippets</h1>
        <ul>
            <li><a href="#escstan"><code>eight_schools_centered.stan</code></a></li>
            <li><a href="#escstanpy"><code>eight_schools_centered_stan.py</code></a></li>
            <li><a href="#escpymc"><code>eight_schools_centered_pymc.py</code></a></li>
            <li><a href="#escjulia"><code>eight_schools_centered.jl</code></a></li>
        </ul>
        <ul>
            <li><a href="#mchmc"><code>mchmc.jl</code></a></li>
            <li><a href="#ess"><code>ess.jl</code></a></li>
            <li><a href="#submodel"><code>submodel.jl</code></a></li>
            <li><a href="#ad"><code>ad.jl</code></a></li>
        </ul>

        <br><hr>

        <h1>Links</h1>
        <ul>
            <li><a href="https://github.com/penelopeysm">Me on GitHub</a></li>
        </ul>
        <ul>
            <li><a href="https://turinglang.org/">Turing.jl docs</a></li>
            <li><a href="https://github.com/TuringLang">Turing.jl on GitHub</a></li>
        </ul>
        <ul>
            <li><a href="https://turing.ac.uk">The Alan Turing Institute</a></li>
            <li><a href="https://alan-turing-institute.github.io/REG/">Research Software Engineering at the Turing</a> <span class="small">(I made this website :))</span></li>
        </ul>

        <br><hr>

        <h1>Code snippets</h1>

        <h2 id="escstan">eight_schools_centered.stan</h2>
        <a href="#toc">(Back to top)</a>
        <p>(This was taken from <a href="https://github.com/stan-dev/posteriordb/blob/master/posterior_database/models/stan/eight_schools_centered.stan">PosteriorDB</a>.)</p>

        <pre><code class="language-stan">data {
  int<lower=0> J; // number of schools
  array[J] real y; // estimated treatment
  array[J] real<lower=0> sigma; // std of estimated effect
}
parameters {
  array[J] real theta; // treatment effect in school j
  real mu; // hyper-parameter of mean
  real<lower=0> tau; // hyper-parameter of sdv
}
model {
  tau ~ cauchy(0, 5); // a non-informative prior
  theta ~ normal(mu, tau);
  y ~ normal(theta, sigma);
  mu ~ normal(0, 5);
}</code></pre>


        <h2 id="escstanpy">eight_schools_centered_stan.py</h2>
        <a href="#toc">(Back to top)</a>
        <p>You will need to have <a href="#escstan"><code>eight_schools_centered.stan</code></a> in the same directory as this file. Then create a virtual environment with the <code>cmdstanpy</code> package installed, and run (from the Python REPL) <code>cmdstanpy.install_cmdstan()</code> to set up Stan.</p>
        <pre><code class="language-python">from cmdstanpy import CmdStanModel
from pathlib import Path
import time

DATA = {
    "y": [28, 8, -3, 7, -1, 1, 18, 12],
    "sigma": [15, 10, 16, 11, 9, 11, 10, 18],
    "J": 8,
}

def main():
    stan_file = Path(__file__).parent / "eight_schools_centered.stan"
    model = CmdStanModel(stan_file=stan_file)
    x = time.time()
    fit = model.sample(data=DATA, chains=1,
                       iter_warmup=10000, save_warmup=False,
                       iter_sampling=10000, thin=10)
    y = time.time()
    print(fit.summary())
    print(f"Time taken: {y - x} seconds")


if __name__ == "__main__":
    main()</code></pre>


        <h2 id="escjulia">eight_schools_centered.jl</h2>
        <a href="#toc">(Back to top)</a>
        <p>Launch Julia with <code>julia -t8 --project=.</code> and then run <code>]add Turing</code>. Once that is done, press Backspace to re-enter the REPL mode. You can then run the commands in this file.</p>
        <pre><code class="language-julia">using Turing

J = 8
y = [28, 8, -3, 7, -1, 1, 18, 12]
sigma = [15, 10, 16, 11, 9, 11, 10, 18]

@model function eight_schools_centered(J, y, sigma)
    mu ~ Normal(0, 5)
    tau ~ truncated(Cauchy(0, 5); lower=0)
    theta = Vector{Float64}(undef, J)
    for i in 1:J
        theta[i] ~ Normal(mu, tau)
        y[i] ~ Normal(theta[i], sigma[i])
    end
end

model_esc = eight_schools_centered(J, y, sigma)

chain = sample(model_esc, NUTS(), MCMCThreads(), 1000, 10; num_warmup=10_000, thinning=10)</pre></code>

        <h2 id="escpymc">eight_schools_centered_pymc.py</h2>
        <a href="#toc">(Back to top)</a>
        <p>You will need a virtual environment with the <code>pymc</code> package installed.</p>

        <pre><code class="language-python">import pymc as pm
import numpy as np
import time

J = 8
y = np.array([28, 8, -3, 7, -1, 1, 18, 12])
sigma = np.array([15, 10, 16, 11, 9, 11, 10, 18])

def main():
    with pm.Model() as eight_schools_centered:
        mu = pm.Normal("mu", 0, 5)
        tau = pm.HalfCauchy("tau", 5)
        theta = pm.Normal("theta", mu, tau, shape=J)
        obs = pm.Normal("obs", theta, sigma, observed=y)

        start = time.time()
        trace = pm.sample(draws=10000, tune=10000, chains=1)
        end = time.time()

    print(f"took {end - start} seconds")

if __name__ == "__main__":
    main()</code></pre>

        <h2 id="mchmc">mchmc.jl</h2>
        <a href="#toc">(Back to top)</a>
        <p>Go back to the same directory that you ran the Julia code in. If you run <code>julia --project=.</code> it will activate the same environment as previously. You can then run all of the code below in the REPL.</p>

        <pre><code class="language-julia">using Turing, MicroCanonicalHMC

J = 8
y = [28, 8, -3, 7, -1, 1, 18, 12]
sigma = [15, 10, 16, 11, 9, 11, 10, 18]

@model function eight_schools_centered(J, y, sigma)
    mu ~ Normal(0, 5)
    tau ~ truncated(Cauchy(0, 5); lower=0)
    theta = Vector{Float64}(undef, J)
    for i in 1:J
        theta[i] ~ Normal(mu, tau)
        y[i] ~ Normal(theta[i], sigma[i])
    end
end

model_esc = eight_schools_centered(J, y, sigma)
sample(model_esnc, NUTS(), 2000)

using MicroCanonicalHMC
mchmc_sampler = externalsampler(MCHMC(10000, 0.001))
sample(model_esnc, mchmc_sampler, 2000)</pre></code>

        <h2 id="ess">ess.jl</h2>
        <a href="#toc">(Back to top)</a>
        <p>You will need a few more dependencies: <code>]add AbstractGPs LogExpFunctions SliceSampling</code></p>

        <pre><code class="language-julia">using AbstractGPs, LogExpFunctions, Turing, SliceSampling

N = 10
xs = ColVecs(rand(2, N))
ys = mean.(xs) .< rand(length(xs))

@model function gp(points)
    var ~ Exponential(1)
    scale ~ Exponential(1)
    f = GP(var * with_lengthscale(SEKernel(), scale))
    preds ~ f(points, 1e-8)
    y ~ product_distribution(BernoulliLogit.(preds))
end

model = dense_gp(xs) | (; y = ys)

sample(model, NUTS(), 1000)

sample(model, Gibbs(:preds => ESS(), (:var, :scale) => externalsampler(HitAndRun(SliceSteppingOut(4.0)))), 1000)</code></pre>


        <h2 id="submodel">submodel.jl</h2>
        <a href="#toc">(Back to top)</a>

        <pre><code class="language-julia">using Turing

J = 8
y = [28, 8, -3, 7, -1, 1, 18, 12]
sigma = [15, 10, 16, 11, 9, 11, 10, 18]

@model function eight_schools_priors()
    mu ~ Normal(0, 5)
    tau ~ truncated(Cauchy(0, 5); lower=0)
    return (mu=mu, tau=tau)
end

@model function eight_schools_centered(J, y, sigma)
    priors ~ to_submodel(eight_schools_priors())
    theta = Vector{Float64}(undef, J)
    for i in 1:J
        theta[i] ~ Normal(priors.mu, priors.tau)
        y[i] ~ Normal(theta[i], sigma[i])
    end
end

@model function eight_schools_noncentered(J, y, sigma)
    priors ~ to_submodel(eight_schools_priors())
    theta_trans = Vector{Float64}(undef, J)
    for i in 1:J
        theta_trans[i] ~ Normal(0, 1)
        theta = theta_trans[i] * priors.tau + priors.mu
        y[i] ~ Normal(theta, sigma[i])
    end
end

model_esc = eight_schools_centered(J, y, sigma)
chain_esc = sample(model_esc, NUTS(), 2000)

model_esnc = eight_schools_noncentered(J, y, sigma)
chain_esnc = sample(model_esnc, NUTS(), 2000)</code></pre>

        <h2 id="ad">ad.jl</h2>
        <a href="#toc">(Back to top)</a>
        <p>Again, a few more dependencies: <code>]add ADTypes Enzyme</code></p>

        <pre><code class="language-julia">using Turing, ADTypes
import Enzyme: set_runtime_activity, Reverse

@model function eight_schools_noncentered(J, y, sigma)
    mu ~ Normal(0, 5)
    tau ~ truncated(Cauchy(0, 5); lower=0)
    theta_trans = Vector{Float64}(undef, J)
    for i in 1:J
        theta_trans[i] ~ Normal(0, 1)
        theta = theta_trans[i] * tau + mu
        y[i] ~ Normal(theta, sigma[i])
    end
end

model = eight_schools_noncentered(J, y, sigma)

forwarddiff = AutoForwardDiff()
chain = sample(model, NUTS(; adtype=forwarddiff), 2000)

enzyme_reverse = AutoEnzyme(; mode=set_runtime_activity(Reverse, true))
chain = sample(model, NUTS(; adtype=enzyme_reverse), 2000)</code></pre>


    </body>
</html>
